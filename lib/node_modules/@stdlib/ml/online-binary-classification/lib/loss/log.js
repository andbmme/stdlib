/**
* @license Apache-2.0
*
* Copyright (c) 2018 The Stdlib Authors.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*    http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

'use strict';

// MODULES //

var exp = require( '@stdlib/math/base/special/exp' );
var regularize = require( './../regularize.js' );


// MAIN //

/**
* Given a new observation `(x,y)`, updates the weights using the log loss.
*
* ## Notes
*
* The log loss is defined as
*
* ```tex
* \ln( 1 + \exp( -y w^\intercal x ) )
* ```
*
* @private
* @param {WeightVector} weights - current model coefficients
* @param {NumericArray} x - feature vector
* @param {number} y - response value
* @param {PositiveNumber} eta - current learning rate
* @param {NonNegativeNumber} lambda - regularization parameter
*/
function logLoss( weights, x, y, eta, lambda ) {
	var loss = y / ( 1.0 + exp( y * weights.innerProduct( x ) ) );

	// Perform L2 regularization...
	regularize( weights, lambda, eta );

	weights.add( x, ( eta * loss ) );
}


// EXPORTS //

module.exports = logLoss;
